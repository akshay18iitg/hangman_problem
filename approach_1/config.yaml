training:
  batch_size: 32
  learning_rate: 0.001
  loss: huber
  num_episodes: 100
  train_steps: 10000
  warmup_episode: 2
  save_freq: 1000

optimizer:
  name: adam
  lr_min: 0.0001
  lr_decay: 5000

rl:
  gamma: 0.99
  max_steps_per_episode: 30
  target_model_update_episodes: 10
  max_queue_length: 50000

epsilon:
  max_epsilon: 1
  min_epsilon: 0.1
  decay_epsilon: 400
